{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a file from GCS bucket into BQ using Google APIs\n",
    "Below is some sample code w/documentation that is runnable from within this notebook on loading a file from a gcs bucket into bq WITHOUT using pandas. <br>\n",
    "Feel free to run this as manytimes as you would like everything is done in lab-e00.  Also, below are some good links with examples.\n",
    "\n",
    "> Links: \n",
    "- GCP-Python Client Library: https://google-cloud.readthedocs.io/en/latest/index.html   ***Highly Recommended\n",
    "- Introduction to loading data into BQ: https://cloud.google.com/bigquery/docs/loading-data\n",
    "- GCP Authentication: https://google-auth.readthedocs.io/en/latest/index.html\n",
    "- BQ Batch/Interactive Queries: https://cloud.google.com/bigquery/docs/running-queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 15d7fef6-e551-4e83-a0e7-338eebdd491e\n",
      "Job finished.\n",
      "Loaded 14023202 rows.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Define project parms; datasets, tables, etc\n",
    "stg_project = 'lab-e00-ent'\n",
    "stg_dataset_id = 'temporary'\n",
    "tgt_dataset_id = 'discovery'\n",
    "stg_table = 'example_stg_01'\n",
    "tgt_table = 'example_tgt_01'\n",
    "cred_file = '/data/keys/lab-e00.json'\n",
    "gcs_bucket = 'fd_testing'\n",
    "filename = 'PandC_RPM_Mailed_Triggers.csv'\n",
    "\n",
    "\n",
    "def load_file_to_bq():\n",
    "\n",
    "    # Instantiate a credential object from serevice accoutn JSON file\n",
    "    # You may also see 'from_service_account_json'.. file is what I have seen mainly used\n",
    "    # https://google-auth.readthedocs.io/en/latest/_modules/google/oauth2/service_account.html\n",
    "    stg_credentials = service_account.Credentials.from_service_account_file(cred_file)\n",
    "\n",
    "    # Instantiate a BQ Client from project and credentials\n",
    "    # Here we are calling the client stg_client becuase we may create another client for a different project. eg. moving data from LAB to VALUE\n",
    "    stg_client = bigquery.Client(project=stg_project, credentials=stg_credentials)\n",
    "\n",
    "    # Create a dataset/reference object.  Will used this instantiated object to set/create table name in the desired dataset\n",
    "    dataset_ref = stg_client.dataset(stg_dataset_id)\n",
    "\n",
    "    # Get defined BQ job configuration   https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.job.LoadJobConfig.html\n",
    "    # This will load default config and allow us to define any parmaters for this load\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "\n",
    "    # Set job config to truncate the current table if it exists\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "    # Define the schema of the BQ table\n",
    "    job_config.schema = [\n",
    "        bigquery.SchemaField(\"PM_FIRST_NAME\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_MIDDLE_INITIAL\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_LAST_NAME\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_NAME_SUFFIX\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_ADDRESS_LINE1\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_ADDRESS_LINE2\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_CITY\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_STATE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_ZIP\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_ZIP4\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FILLER1\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CAMPAIGN_CODE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"MODEL_1_DECILE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CAMPAIGN_SOURCE_CD\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CAMPAIGN_SEQUENCE_NUMBER\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CAMPAIGN_CELL_CD\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CAMPAIGN_MAILDATE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"ASSIST_SCORE_CD\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"DATA_SOURCE_INDICATOR\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"POC_CODE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"PROMOTION_GROUP_ID\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CREATIVE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TARGET_TYPE_CD\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"COST\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RPM_IID\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FILLER2\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FILLER3\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"add_date\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"MEMBER_TENURE\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"MULTI_DRIVER\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"GOOD_STUDENT\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"MPD_AUTO_FL\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"MPD_AUTO_GA_TN\", \"STRING\")\n",
    "    ]\n",
    "\n",
    "    # job_config.source_format = bigquery.SourceFormat.CSV    (This is optional as it is the default)\n",
    "\n",
    "    # Define the uri of the bucket and filename\n",
    "    uri = \"gs://{}/{}\".format(gcs_bucket,filename)  # \"gs://fd_testing/PandC_RPM_Mailed_Triggers.csv\"\n",
    "\n",
    "    # Instantiate based on our modified configuration and provide the destination table name\n",
    "    load_job = stg_client.load_table_from_uri(\n",
    "        uri, dataset_ref.table(stg_table), job_config=job_config\n",
    "    )  # API request\n",
    "\n",
    "    print(\"Starting job {}\".format(load_job.job_id))\n",
    "\n",
    "    load_job.result()  # Waits for table load to complete.\n",
    "    print(\"Job finished.\")\n",
    "\n",
    "    # Get results and display.. This is a bit misleading as it will count all rows in the table and not just what you are loading (appends)\n",
    "    destination_table = stg_client.get_table(dataset_ref.table(stg_table))\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    try:\n",
    "        load_file_to_bq()\n",
    "    except Exception as e:\n",
    "        s = str(e)\n",
    "        print(\"ERROR: \" + s)\n",
    "        raise RuntimeError(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
